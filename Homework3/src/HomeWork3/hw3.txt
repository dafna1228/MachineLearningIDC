1. We expect feature scaling to have a positive effect on our kNN algorithm, because kNN uses distance.
when calculating distance, we use all the features, so we want the values to have the same weight, because we assume they both
carry the same importance.
For Example,say some feature gets values in range 0 - 1, and another feature gets values in range 100 - 1000, we want
both features to have the same weight in the distance calculation.

There is no need to scale features in Decision Tree, because the algorithm only compares values of the same feature
so having the values scaled would not give us more accurate results

2. We shouldn't use this procedure on our dataset because our class attribute receives continuous and not discrete values - we use regression and not classification.
The forward/backward filtering algorithm checks for every instance if it's classified correctly by the dataset, meaning it must be EQUAL to the class value. 
The chances for that to occur in continuous values are quite slim, meaning that most likely, almost no instance will be removed or maybe even none, so the filtering won't be effective. 
